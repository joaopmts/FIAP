{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg5ZPMO1jo4L"
      },
      "source": [
        "#**Trabalho final - Simulador de ChatBot com GenAI e VectorDB**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXvR5XhTOG0O"
      },
      "source": [
        "**Nota de atenção:**\n",
        "- Leia com atenção o descritivo do trabalho e as orientações do template.\n",
        "- O trabalho deve ser entregue **respeitando a estrutura do arquivo de template**, utilizando o notebook \"Template Trabalho final - Simulador de ChatBot.ipynb\" e compactado no formato .zip.\n",
        "- Deve haver apenas um arquivo no formato .ipynb, consolidando todo o trabalho."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDbi6PDS9MYO"
      },
      "source": [
        "**Participantes (RM - NOME):**<br>\n",
        "João Paulo Martins Rodrigues – RM 364668<br>\n",
        "Herivelto Raimundo Lemos de Macedo Junior – RM 364212<br>\n",
        "Evaldo Loiola Mota Junior – RM 364056<br>\n",
        "Bruno Gomes Nogueira – RM 364457<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWJpH4UFYToR"
      },
      "source": [
        "###**Caso de uso - Marketplace de classificados veículos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN3KUUndYagl"
      },
      "source": [
        "Imagine que você trabalha na empresa **iAutos** que tem como produto principal um marketplace de classificados de veículos e você como um Engenheiro de Dados, tem a missão de ajudar a empresa a oferecer um melhor serviço para seus clientes (vendedores e compradores)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GntkxRZeXqjv"
      },
      "source": [
        "Contexto:\n",
        "- Sua empresa oferece um serviço (site/plataforma) de classificados de veículos (semelhantes aos marketplaces convencionais, mas focado em vendas de veículos), onde os vendedores (sellers) podem cadastrar e anunciar seus veículos, e compradores (buyers) podem buscar veículos de seu interesse e contatar os vendedores para negociar os veículos de seu interesse.\n",
        "- Diariamente a empresa recebe muitos chamados de dúvidas sobre as regras de publicação de veículos e regras de uso do produto.\n",
        "- Veja mais detalhes das regras do documento de [Quem Somos e Políticas de Uso](https://drive.google.com/file/d/1-ZpUOl8OA4lxa8CJ6auT42hSxaF3jclk) (em PDF).\n",
        "\n",
        "---\n",
        "Como podemos ajudar a empresa?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIOKUZecY1N2"
      },
      "source": [
        "###**Desafio**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KiJ9c6VTP_R"
      },
      "source": [
        "A ideia é criar um ChatBot mais \"turbinado\" do que praticamos nas aulas.\n",
        "Esse ChatBot será ser responsável por atender e responder as dúvidas dos clientes sobre o marketplace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1p5BJoZsObI"
      },
      "source": [
        "Criem um **ChatBot demonstrativo** usando IA Generativa para criar um novo **canal de atendimento** para tirar dúvidas dos clientes referente a plataforma, políticas de uso e publicação, para isso considere as orientações abaixo:\n",
        "\n",
        "- Utilizem o framework do **LangChain** para criar a lógica do ChatBot, gerenciar a conexão com o modelo LLM e modelo de Embedding, para gerenciar o ChromaDB com base no contexto e para gerenciar a memória do agente.\n",
        "- Usem como contexto o arquivo PDF [Quem Somos e Políticas de Uso](https://drive.google.com/file/d/1-ZpUOl8OA4lxa8CJ6auT42hSxaF3jclk).\n",
        "- Criem o VectorDB com o ChromaDB e com base no contexto do PDF.\n",
        "  - Obs.: Não necessariamente precisa carregar o PDF, fiquem a vontade para definirem a melhor estratégia.\n",
        "- Utilizem as boas práticas de Prompt Engineering para criar o template do prompt para o serviço e gerenciar a conversa.\n",
        "- Utilizem como base e referência todos os materiais apresentados, tanto de Generative AI quanto de Database for GenAI.\n",
        "  - Estruturem bem o trabalho, organizem em funções, expliquem e documentem bem os códigos e decisões.\n",
        "- Fiquem a vontade de complementar o contexto e o prompt para otimizar o serviço.\n",
        "- Fiquem a vontade de trazer técnicas que façam sentido e complemente o trabalho.\n",
        "\n",
        "### Dicas:\n",
        "- Comecem os desenvolvimentos de forma simples, testando os componentes e vá aumentando a complexidade gradativamente.\n",
        "- Utilizem os modelos LLMs da OpenAI ou da Azure com OpenAI.\n",
        "\n",
        "###**Orientações:**\n",
        "\n",
        "---\n",
        "####**Usem o Google Colab com Python e esse template para desenvolverem o trabalho.**\n",
        "---\n",
        "\n",
        "**1. Desenvolvimento e testes**, nessa parte é onde vocês podem explorar o desenvolvimento do trabalho aplicando as técnicas, testando as ferramentas e serviços de GenAI.\n",
        "  - Explorem diferentes formas de tratar o problema. Comecem testando os componentes e definindo a melhor estratégia.\n",
        "  - Testem as ferramentas, framework, APIs e técnicas de prompt engineering.\n",
        "  - Fiquem à vontade para explorar os serviços e frameworks vistos em aula: API da OpenAI Platform, API da Azure AI Foundry, LangChain e outros.\n",
        "  - Sejam criativos, mas não precisa de muita complexidade e podem explorar outras formas de desenvolver.\n",
        "  - Expliquem as decisões e racional do desenvolvimento. **Abuse dos comentários**.\n",
        "\n",
        "**2. Processo final**, aqui nessa parte separem apenas o processo final com um pipeline completo para o ChatBot, desde a instalação das bibliotecas até a simulação.\n",
        "  - Organizem em funções que façam sentido.\n",
        "  - Resultado esperado: Um processo estruturado utilizando LangChain e ChromaDB, criando um VectorDB com uma boa estratégia de indexação e busca (retriever), uma simulação do ChatBot (pode ser estruturando uma API ou alguma lógica para simular uma conversa).\n",
        "  - Exemplos: Deixem e/ou compartilhem no notebook exemplos de conversas.\n",
        "  - Testem bem esse pipeline antes, pois o professor tentará executar o processo para validar a implementação.\n",
        "\n",
        "###**Avaliação:**\n",
        "O trabalho será avaliado pelas seguintes diretrizes:\n",
        "  - Demonstração de conhecimento com os temas abordados em sala de aula.\n",
        "  - Utilização correta dos frameworks, APIs e aplicação das técnicas de prompt engineering.\n",
        "  - Organização, comentários e explicação certamente vão ajudar na nota.\n",
        "  - Resultado esperado seguindo as orientações do professor nesse template.\n",
        "\n",
        "###**Atenção:**\n",
        "- Usem a conta da **Azure AI Foundry** ou da **OpenAI Platform** para desenvolverem o trabalho, mas dê preferência para a conta da Azure por causa dos limites de crédito. **Não deixem suas credenciais no trabalho, por favor!**\n",
        "- Trabalhos iguais são passíveis de reprovação ou desconto de nota.\n",
        "- Respeitem a estrutura do template fornecido pelo professor.\n",
        "- Limite de 2 a 4 pessoas por grupo, de preferência o mesmo grupo do Startup One."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EISVWz-KmH5D"
      },
      "source": [
        "##**1. Desenvolvimento e testes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh9AhDTBmH5D"
      },
      "source": [
        "Desenvolva aqui:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instalacao de bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chromadb in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.3.0)\n",
            "Requirement already satisfied: build>=1.0.3 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (2.11.7)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (2.3.2)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (4.15.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (14.2.0)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.5)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\joao pc\\appdata\\roaming\\python\\python313\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\joao pc\\appdata\\roaming\\python\\python313\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: packaging>=19.1 in c:\\users\\joao pc\\appdata\\roaming\\python\\python313\\site-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\joao pc\\appdata\\roaming\\python\\python313\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
            "Requirement already satisfied: anyio in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.28.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.42.1)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: coloredlogs in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.71.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.38.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.59b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\joao pc\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (1.0.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.10.0)\n",
            "Requirement already satisfied: shellingham in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (0.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: pyreadline3 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\joao pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf==6.0.0 --quiet\n",
        "!pip install pdfminer.six==20250506 --quiet\n",
        "!pip install langchain==0.3.27 langchain_community==0.3.27 langchain-openai==0.3.27 --quiet\n",
        "!pip install langchain-chroma==0.2.5 chromadb-client==1.0.20 --quiet\n",
        "!pip install pyngrok==7.3.0 --quiet\n",
        "!pip install fastapi==0.116.1 uvicorn==0.35.0 nest_asyncio==1.6.0 --quiet\n",
        "!pip install chromadb\n",
        "!pip install python-dotenv tiktoken requests pydantic psutil --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importacao Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import tiktoken\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import PDFMinerLoader\n",
        "import requests\n",
        "from fastapi import FastAPI, Request\n",
        "from fastapi.responses import HTMLResponse\n",
        "from pydantic import BaseModel\n",
        "import uuid\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "import chromadb\n",
        "import langchain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.schema import Document\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate, MessagesPlaceholder\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from pyngrok import ngrok, conf\n",
        "import os, sys, time, psutil, socket, subprocess, shutil\n",
        "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chaves e Parametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "KEY_NGROK = \"34piJFJVU1Si8AFxTsi8AqwgvOd_7jo5qV2hbPtayYsLbUHBQ\" \n",
        "\n",
        "OPENAI_API_KEY = \"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\"\n",
        "\n",
        "azure_api_key = \"2YtgC1igEt7izb0fsR2LsNwKmpw6uSiwpc2oRpXziXR2Fe24vFXsJQQJ99BHACHYHv6XJ3w3AAABACOGs58E\"\n",
        "azure_endpoint = \"https://openai-dourado.openai.azure.com/\"\n",
        "llm_deployment_model = \"gpt-4.1\"\n",
        "llm_api_version = \"2025-01-01-preview\"\n",
        "\n",
        "emb_deployment_model = \"text-embedding-3-small\" \n",
        "emb_api_version = \"2024-02-01\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se quiser ir pela OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\JOAO PC\\AppData\\Local\\Temp\\ipykernel_6432\\4130847035.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(\n",
            "C:\\Users\\JOAO PC\\AppData\\Local\\Temp\\ipykernel_6432\\4130847035.py:9: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embedding_model = OpenAIEmbeddings(\n"
          ]
        }
      ],
      "source": [
        "# Modelo LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.5,\n",
        "    openai_api_key=OPENAI_API_KEY\n",
        ")\n",
        "\n",
        "# Define qual o modelo de embeddings, no caso vamos usar um modelo da OpenAI - text-embedding-3-small\n",
        "embedding_model = OpenAIEmbeddings(\n",
        "    openai_api_key = OPENAI_API_KEY,\n",
        "    model = 'text-embedding-3-small'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se quiser ir pela Azure, pela ordem coloquei para usar a Azure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = AzureChatOpenAI(\n",
        "    azure_endpoint=azure_endpoint,\n",
        "    azure_deployment=llm_deployment_model,\n",
        "    openai_api_key=azure_api_key,\n",
        "    openai_api_version=llm_api_version,\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "embedding_model = AzureOpenAIEmbeddings(\n",
        "    azure_endpoint=azure_endpoint,\n",
        "    azure_deployment=emb_deployment_model,\n",
        "    openai_api_key=azure_api_key,\n",
        "    openai_api_version=emb_api_version,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definição e criação do ChromaDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YVKTu4momOr0"
      },
      "outputs": [],
      "source": [
        "CHROMA_HOST = \"127.0.0.1\" \n",
        "CHROMA_PORT = 8000\n",
        "\n",
        "def is_port_in_use(port, host=\"127.0.0.1\"): #checa se a porta esta em uso\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.settimeout(0.5)\n",
        "        return s.connect_ex((host, port)) == 0\n",
        "\n",
        "def wait_for_port(port, host=\"127.0.0.1\", timeout=30): #aguarda retorno da porta\n",
        "    start = time.time()\n",
        "    while time.time() - start < timeout:\n",
        "        if is_port_in_use(port, host):\n",
        "            return True\n",
        "        time.sleep(0.5)\n",
        "    return False\n",
        "\n",
        "def build_chroma_cmd(host, port): #cria funcao para chromadb\n",
        "        chroma_exe = os.path.join(os.path.dirname(sys.executable), \"Scripts\", \"chroma.exe\")\n",
        "        return [chroma_exe, \"run\", \"--host\", host, \"--port\", str(port)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3t5QyQ_UmOpl"
      },
      "outputs": [],
      "source": [
        "chroma_exe = os.path.join(os.path.dirname(sys.executable), \"Scripts\", \"chroma.exe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rEL7AhL3mOnM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\JOAO PC\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Scripts\\\\chroma.exe'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chroma_exe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.path.exists(chroma_exe) #precisa retornar True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "chroma = build_chroma_cmd(CHROMA_HOST, CHROMA_PORT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['c:\\\\Users\\\\JOAO PC\\\\AppData\\\\Local\\\\Program...>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subprocess.Popen(chroma, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT) #cria o chroma db\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wait_for_port(CHROMA_PORT) #precisa retornar true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verificando status do servidor...\n",
            "{\"nanosecond heartbeat\":1761943094310527100}\n",
            "\n",
            "Se a resposta acima for '{\"nanosecond heartbeat\":...}', o servidor está no ar!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100    44  100    44    0     0  33820      0 --:--:-- --:--:-- --:--:-- 44000\n"
          ]
        }
      ],
      "source": [
        "# Verifica se o servidor está respondendo (opcional, mas recomendado)\n",
        "print(\"Verificando status do servidor...\")\n",
        "!curl http://127.0.0.1:8000/api/v2/heartbeat\n",
        "print(\"\\nSe a resposta acima for '{\\\"nanosecond heartbeat\\\":...}', o servidor está no ar!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configurando e iniciando o Ngrok\n",
            "Servidor Chroma está online e acessível na URL: NgrokTunnel: \"https://operculate-vernon-unmissed.ngrok-free.dev\" -> \"http://localhost:8000\"\n"
          ]
        }
      ],
      "source": [
        "# Associar o Servidor Chroma com o Ngrok\n",
        "# Configurando e iniciando o Ngrok\n",
        "print(\"Configurando e iniciando o Ngrok\")\n",
        "ngrok.set_auth_token(KEY_NGROK)\n",
        "#conf.get_default().auth_token = KEY_NGROK\n",
        "\n",
        "# Mata qualquer túnel anterior para garantir um início limpo\n",
        "try:\n",
        "  ngrok.kill()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# Expor o servidor com Ngrok\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"Servidor Chroma está online e acessível na URL: {public_url}\")\n",
        "# Inicia o túnel na porta 8000, onde nosso servidor Chroma está escutando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'https://operculate-vernon-unmissed.ngrok-free.dev'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "public_url.public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"nanosecond heartbeat\":1761943095814817000}\n",
            "\n",
            "Se a resposta acima for '{\"nanosecond heartbeat\":...}', o servidor está no ar! 🚀\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100    44  100    44    0     0     75      0 --:--:-- --:--:-- --:--:--    75\n"
          ]
        }
      ],
      "source": [
        "url = public_url.public_url  \n",
        "\n",
        "# testa o endpoint de heartbeat\n",
        "!curl {url}/api/v2/heartbeat\n",
        "print(\"\\nSe a resposta acima for '{\\\"nanosecond heartbeat\\\":...}', o servidor está no ar! 🚀\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ PDF baixado com sucesso!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_id = \"1-ZpUOl8OA4lxa8CJ6auT42hSxaF3jclk\" #pelo link do documento, obvtive o file id do pdf e baseado na aula 1 fiz a importacao pelo pdf miner loader para melhor preservacao da estrutura\n",
        "url_download = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "local_filename = \"quemsomospoliticasdeuso.pdf\"\n",
        "\n",
        "response = requests.get(url_download)\n",
        "response.raise_for_status()\n",
        "\n",
        "with open(local_filename, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(\"✅ PDF baixado com sucesso!\")\n",
        "\n",
        "loader = PDFMinerLoader(local_filename)\n",
        "contexto = loader.load()\n",
        "\n",
        "len(contexto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ O PDF foi dividido em 4 chunks (documentos menores).\n",
            "📘 Exemplo de chunk:\n",
            "\n",
            "iAutos - Marketplace de classificados \n",
            "veículos \n",
            "\n",
            "Conectando compradores e vendedores de veículos com segurança e \n",
            "confiança. \n",
            "\n",
            "Quem Somos? – iAutos \n",
            "\n",
            "Nossa História \n",
            "\n",
            "O iAutos nasceu com a missão de revolucionar o mercado de classificados de veículos, \n",
            "oferecendo uma plataforma simples, intuitiva e segura para conectar vendedores e \n",
            "compradores em todo o Brasil. \n",
            "\n",
            "Inspirados por marketplaces de referência, mas focados exclusivamente em veículos, \n",
            "criamos um espaço onde a negociação é clara, direta e protegida, garantindo que todos os \n",
            "usuários possam realizar bons negócios com tranquilidade. \n",
            "\n",
            "O que fazemos? \n",
            "\n",
            "O iAutos é um marketplace especializado em anúncios de veículos, onde: \n",
            "\n",
            "●  Vendedores podem cadastrar e expor seus veículos a potenciais compradores. \n",
            "\n",
            "●  Compradores podem buscar veículos por tipo, preço, localização e características, \n",
            "\n",
            "solicitando contato com o vendedor diretamente pela plataforma. \n",
            "\n",
            "Nosso compromisso é com a transparência, a experiência do usuário e a segurança, \n",
            "combatendo fraudes e uso indevido para preservar a confiança no ecossistema. \n",
            "\n",
            "Nossa Missão \n",
            "\n",
            "Facilitar a compra e venda de veículos, conectando pessoas com interesses reais de \n",
            "negociação, oferecendo uma experiência de uso fluida, eficiente e segura. \n",
            "\n",
            "Nossos Valores\n",
            "\f●  Segurança: Protegemos a comunicação e os dados dos nossos usuários. \n",
            "\n",
            "●  Transparência: Mantemos regras claras e aplicamos políticas de uso justas. \n",
            "\n",
            "● \n",
            "\n",
            "Inovação: Melhoramos continuamente a plataforma para oferecer a melhor \n",
            "experiência. \n",
            "\n",
            "●  Compromisso com a comunidade: Criamos um ambiente confiável para \n",
            "\n",
            "compradores e vendedores. \n",
            "\n",
            "Por que escolher o iAutos?\n"
          ]
        }
      ],
      "source": [
        "# Escolhe o tokenizer utilizando o mesmo método do modelo de Embeddings\n",
        "encoding = tiktoken.encoding_for_model(\"text-embedding-3-small\")\n",
        "\n",
        "# Função que conta tokens\n",
        "def fn_conta_token(text: str) -> int:\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,        # máximo de tokens por chunk\n",
        "    chunk_overlap = 50,      # sobreposição entre chunks\n",
        "    length_function = fn_conta_token,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "conteudo_completo = \" \".join([doc.page_content for doc in contexto])\n",
        "\n",
        "# O método create_documents divide e retorna uma lista de objetos Document\n",
        "documents = text_splitter.create_documents([conteudo_completo])\n",
        "\n",
        "print(f\"✅ O PDF foi dividido em {len(documents)} chunks (documentos menores).\")\n",
        "print(\"📘 Exemplo de chunk:\\n\")\n",
        "print(documents[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "client_chromadb = chromadb.HttpClient(\n",
        "    host = CHROMA_HOST\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# O nome da \"coleção\" no servidor. Pense nisso como o nome de uma tabela em um banco de dados.\n",
        "CHROMADB_COLLECTION_NAME = \"chromadb_vactorstore_iautos\"\n",
        "\n",
        "# Cria o Vectorstore com o Chroma a partir dos documentos divididos\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents = documents,\n",
        "    embedding = embedding_model,\n",
        "    client = client_chromadb,  # Passamos o \"client\" em vez do persist_directory\n",
        "    collection_name = CHROMADB_COLLECTION_NAME\n",
        ")\n",
        "\n",
        "# Instancia o retriever (podemos controlar o número de chunks do retorno da análise de similaridade)\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type = \"similarity\",   # similarity por \"mmr\" - (max marginal relevance) - pode trazer mais diversidade nos resultados\n",
        "    search_kwargs = {\"k\": 3}      # define quantos chunks vão retornar\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iAutos - Marketplace de classificados \n",
            "veículos \n",
            "\n",
            "Conectando compradores e vendedores de veículos com segurança e \n",
            "confiança. \n",
            "\n",
            "Quem Somos? – iAutos \n",
            "\n",
            "Nossa História \n",
            "\n",
            "O iAutos nasceu com a missão de revolucionar o mercado de classificados de veículos, \n",
            "oferecendo uma plataforma simples, intuitiva e segura para conectar vendedores e \n",
            "compradores em todo o Brasil. \n",
            "\n",
            "Inspirados por marketplaces de referência, mas focados exclusivamente em veículos, \n",
            "criamos um espaço onde a negociação é clara, direta e protegida, garantindo que todos os \n",
            "usuários possam realizar bons negócios com tranquilidade. \n",
            "\n",
            "O que fazemos? \n",
            "\n",
            "O iAutos é um marketplace especializado em anúncios de veículos, onde: \n",
            "\n",
            "●  Vendedores podem cadastrar e expor seus veículos a potenciais compradores. \n",
            "\n",
            "●  Compradores podem buscar veículos por tipo, preço, localização e características, \n",
            "\n",
            "solicitando contato com o vendedor diretamente pela plataforma. \n",
            "\n",
            "Nosso compromisso é com a transparência, a experiência do usuário e a segurança, \n",
            "combatendo fraudes e uso indevido para preservar a confiança no ecossistema. \n",
            "\n",
            "Nossa Missão \n",
            "\n",
            "Facilitar a compra e venda de veículos, conectando pessoas com interesses reais de \n",
            "negociação, oferecendo uma experiência de uso fluida, eficiente e segura. \n",
            "\n",
            "Nossos Valores\n",
            "\f●  Segurança: Protegemos a comunicação e os dados dos nossos usuários. \n",
            "\n",
            "●  Transparência: Mantemos regras claras e aplicamos políticas de uso justas. \n",
            "\n",
            "● \n",
            "\n",
            "Inovação: Melhoramos continuamente a plataforma para oferecer a melhor \n",
            "experiência. \n",
            "\n",
            "●  Compromisso com a comunidade: Criamos um ambiente confiável para \n",
            "\n",
            "compradores e vendedores. \n",
            "\n",
            "Por que escolher o iAutos?\n",
            "●  Compromisso com a comunidade: Criamos um ambiente confiável para \n",
            "\n",
            "compradores e vendedores. \n",
            "\n",
            "Por que escolher o iAutos? \n",
            "\n",
            "●  Foco exclusivo no segmento automotivo e com ampla cobertura nacional. \n",
            "●  Sistema de proteção de contatos para evitar golpes e coleta indevida de dados. \n",
            "●  Monitoramento ativo para identificar comportamentos suspeitos. \n",
            "●  Equipe dedicada para garantir sua segurança e criar um produto único que atenda \n",
            "\n",
            "sua necessidade. \n",
            "\n",
            "Políticas de Uso \n",
            "\n",
            "Diretrizes para garantir uma experiência segura e confiável \n",
            "\n",
            "1. Objetivo \n",
            "\n",
            "As presentes Políticas de Uso têm como finalidade estabelecer regras e orientações para \n",
            "vendedores e compradores que utilizam o iAutos, garantindo segurança, transparência e \n",
            "integridade nas transações. \n",
            "\n",
            "Essas diretrizes visam oferecer uma melhor experiência para todos dentro da plataforma. \n",
            "\n",
            "2. Definições \n",
            "\n",
            "●  Plataforma / Marketplace: iAutos. \n",
            "●  Clientes: Vendedores (sellers) e compradores (buyers) cadastrados. \n",
            "● \n",
            "●  Leads: Solicitações de contato feitas por compradores para um determinado \n",
            "\n",
            "Itens: Veículos anunciados na plataforma. \n",
            "\n",
            "anúncio de veículo.\n",
            "\f3. Políticas para Vendedores (Sellers) \n",
            "\n",
            "3.1 Veículos permitidos \n",
            "\n",
            "●  Passageiros: Automóveis (sedan, hatch, SUV, picape, minivan), van, furgão, \n",
            "\n",
            "micro-ônibus, ônibus, motonetas, motocicletas, triciclos, quadriciclos. \n",
            "\n",
            "●  Carga: Utilitários, caminhões, camionetas. \n",
            "\n",
            "●  Motorização: Combustão, elétricos e híbridos. \n",
            "\n",
            "3.2 Veículos proibidos\n"
          ]
        }
      ],
      "source": [
        "# Teste da busca por similaridade\n",
        "query = \"O que é a iAutos?\"\n",
        "\n",
        "docs_retornados = vectorstore.similarity_search(query, k=2)\n",
        "print(docs_retornados[0].page_content)\n",
        "print(docs_retornados[1].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feito toda adaptação do system template para o novo cenario da iAutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_template = \"\"\"\n",
        "Você é um assistente virtual inteligente chamado **iAutoBot**, representante oficial do **iAutos**, \n",
        "um marketplace especializado em compra e venda de veículos.\n",
        "\n",
        "# **Seu papel e objetivo:**\n",
        "1. Ajudar usuários a entender o funcionamento do iAutos e suas políticas de uso.\n",
        "2. Responder perguntas sobre quem somos, missão, valores, segurança e regras da plataforma.\n",
        "3. Orientar vendedores e compradores sobre práticas corretas e evitar fraudes.\n",
        "4. Manter uma comunicação empática, profissional e segura, transmitindo confiança.\n",
        "\n",
        "# **Diretrizes importantes:**\n",
        "- Sempre responda em **português (pt-BR)**.\n",
        "- Use uma linguagem **clara, cordial e profissional**, mas acessível.\n",
        "- Utilize emojis de forma leve e simpática (ex: 🤖🚗🔒✨😉), sem exageros.\n",
        "- Seja **ético e imparcial** — nunca incentive comportamentos fora das políticas.\n",
        "- **Baseie-se APENAS** nas informações disponíveis no contexto abaixo.\n",
        "- Se a resposta não estiver no contexto, diga algo como:\n",
        "  \"_Desculpe, essa informação não está disponível nas políticas oficiais do iAutos, \n",
        "  mas posso te ajudar com outras dúvidas sobre a plataforma!_\"\n",
        "- Mantenha coerência com o histórico da conversa.\n",
        "- Quando o usuário fizer perguntas fora de contexto, redirecione gentilmente para assuntos do iAutos.\n",
        "\n",
        "---\n",
        "\n",
        "**Contexto disponível:**\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessagePromptTemplate.from_template(system_template),   ## regras fixas do assistente\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\", n_messages = 6, optional = True), ## Insere o histórico de conversas aqui (opcional e limitado a N mensagens) / Monta uma lista de mensagens (AIMessage, HumanMessage, SystemMessage)\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")        ## define a entrada do usuário - entrada dinâmica\n",
        "])\n",
        "# optional = True, deixa o histórico como opcional caso esteja vazio para evitar erros\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\JOAO PC\\AppData\\Local\\Temp\\ipykernel_6432\\2282799827.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory_test = ConversationBufferMemory(\n"
          ]
        }
      ],
      "source": [
        "# Configura o memory para manter o histórico da conversa\n",
        "memory_test = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        "    )\n",
        "\n",
        "# Cria a cadeia de conversa com retriever e memória\n",
        "chain_test = ConversationalRetrievalChain.from_llm(\n",
        "    llm = llm,\n",
        "    retriever = retriever,\n",
        "    memory = memory_test,\n",
        "    combine_docs_chain_kwargs = {\"prompt\": chat_prompt},\n",
        "    chain_type = \"stuff\", # O tipo \"stuff\" simplesmente junta os chunks em um único prompt.\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função com o loop de iteração simulando um chat\n",
        "def fn_chat_test():\n",
        "  \"\"\"Função para simular um chat com o assistente\"\"\"\n",
        "  print(\"Iniciado o Chatbot da AutoToya! Digite 'sair' para encerrar.\\n\")\n",
        "\n",
        "  # Pré-carregar uma mensagem de histórico com uma saudação inicial\n",
        "  memory_test.chat_memory.clear() ## limpa o histórico (buffer)\n",
        "  memory_test.chat_memory.add_ai_message(\"Olá! 👋 Seja muito bem-vindo ao iAutos! Sou o AutoBot 🤖, assistente virtual da plataforma.\"\n",
        "        \"Estou aqui para te ajudar a entender como funciona o iAutos — o marketplace seguro e confiável para compra e venda de veículos.\"\n",
        "        \"Quer saber sobre anúncios, regras de uso ou dicas de segurança?\")\n",
        "  print(f\"ToyaBot 🤖: {memory_test.chat_memory.messages[0].content}\")\n",
        "\n",
        "  while True:\n",
        "    user_question = input(\"\\nVocê: \")\n",
        "    if user_question.lower() == \"sair\":\n",
        "        print(\"ToyaBot 🤖: 👋 Conversa encerrada. Até logo! 🚗\")\n",
        "        break\n",
        "    response = chain_test.invoke({\"question\": user_question})\n",
        "    #response = chain_test.run(question = user_question) ## Essa função está depreciada\n",
        "    print(f\"ToyaBot 🤖: {response['answer']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerenciamento de múltiplos usuários (memória por sessão)\n",
        "sessions = {}\n",
        "\n",
        "def get_chat_chain(session_id):\n",
        "    if session_id not in sessions:\n",
        "\n",
        "        # Configura o memory para manter o histórico da conversa\n",
        "        memory = ConversationBufferMemory(\n",
        "            memory_key=\"chat_history\",\n",
        "            return_messages=True\n",
        "            )\n",
        "\n",
        "        # Cria a cadeia de conversa com retriever e memória\n",
        "        chain = ConversationalRetrievalChain.from_llm(\n",
        "            llm = llm,\n",
        "            retriever = retriever,\n",
        "            memory = memory,\n",
        "            combine_docs_chain_kwargs = {\"prompt\": chat_prompt},\n",
        "            chain_type = \"stuff\", # O tipo \"stuff\" simplesmente junta os chunks em um único prompt.\n",
        "            )\n",
        "\n",
        "        # Carrega mensagem inicial\n",
        "        memory.chat_memory.add_ai_message(\"Olá! 👋 Seja muito bem-vindo ao iAutos! Sou o AutoBot 🤖, assistente virtual da plataforma.\"\n",
        "        \"Estou aqui para te ajudar a entender como funciona o iAutos — o marketplace seguro e confiável para compra e venda de veículos.\"\n",
        "        \"Quer saber sobre anúncios, regras de uso ou dicas de segurança?\")\n",
        "\n",
        "        # Gerencia sessão - cada chat vira um objeto chain identificado pelo session_id\n",
        "        sessions[session_id] = chain\n",
        "    return sessions[session_id]\n",
        "\n",
        "# Configura o FastAPI para criar a estrutura de API\n",
        "app = FastAPI(title=\"API - Chatbot AutoBot\", version=\"1.0\")\n",
        "\n",
        "# Estrutura resposta com parse do pydantic\n",
        "class ChatRequest(BaseModel):\n",
        "    session_id: str\n",
        "    question: str\n",
        "\n",
        "# Rota para chamar a função que chama o LLM e toda estrutura do chat (chain, retriever, vectorstore, etc.)\n",
        "@app.post(\"/chat\")\n",
        "def chat(req: ChatRequest):\n",
        "    chain = get_chat_chain(req.session_id)\n",
        "    #resposta = chain.run(question = req.question)\n",
        "    resposta = chain.invoke({\"question\": req.question})\n",
        "    resposta = resposta['answer']\n",
        "    return {\"answer\": resposta}\n",
        "\n",
        "# Rota para inicializar o chat com a mensagem de saudação inicial\n",
        "@app.get(\"/start/{session_id}\")\n",
        "def start(session_id: str):\n",
        "    chain = get_chat_chain(session_id)\n",
        "    msg_inicial = chain.memory.chat_memory.messages[0].content\n",
        "    return {\"answer\": msg_inicial}\n",
        "\n",
        "# Rota principal que renderiza página HTML do chat (simples)\n",
        "@app.get(\"/\", response_class = HTMLResponse)\n",
        "def index():\n",
        "    return \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"pt-BR\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\" />\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "  <title>🤖 iAutoBot Chat - iAutos 🚗</title>\n",
        "  <script src=\"https://cdn.tailwindcss.com\"></script>\n",
        "  <style>\n",
        "    ::-webkit-scrollbar { width: 6px; }\n",
        "    ::-webkit-scrollbar-thumb { background-color: #ccc; border-radius: 3px; }\n",
        "    .chat-bubble { max-width: 80%; padding: 10px 15px; border-radius: 18px; margin: 6px 0; line-height: 1.4; }\n",
        "    .user-msg { background-color: #2563eb; color: white; margin-left: auto; border-bottom-right-radius: 4px; }\n",
        "    .bot-msg { background-color: #f1f5f9; color: #111827; margin-right: auto; border-bottom-left-radius: 4px; }\n",
        "    .fade-in { animation: fadeIn 0.4s ease; }\n",
        "    @keyframes fadeIn { from {opacity: 0; transform: translateY(10px);} to {opacity: 1; transform: translateY(0);} }\n",
        "  </style>\n",
        "</head>\n",
        "<body class=\"bg-gray-50 flex flex-col items-center justify-center min-h-screen\">\n",
        "\n",
        "  <div class=\"bg-white shadow-2xl rounded-2xl w-full max-w-md overflow-hidden\">\n",
        "    <div class=\"bg-blue-600 text-white text-center py-4\">\n",
        "      <h2 class=\"text-xl font-semibold\">🤖 iAutoBot - Assistente do iAutos 🚗</h2>\n",
        "      <p class=\"text-sm opacity-80\">Seu marketplace confiável para veículos</p>\n",
        "    </div>\n",
        "\n",
        "    <div id=\"chat\" class=\"p-4 h-[400px] overflow-y-auto space-y-2 bg-gray-100\"></div>\n",
        "\n",
        "    <div class=\"flex items-center border-t p-3 bg-white\">\n",
        "      <input id=\"msg\" type=\"text\" placeholder=\"Digite sua mensagem...\" \n",
        "             class=\"flex-1 p-2 border border-gray-300 rounded-xl focus:outline-none focus:ring-2 focus:ring-blue-500\" />\n",
        "      <button onclick=\"send()\" \n",
        "              class=\"ml-2 bg-blue-600 hover:bg-blue-700 text-white px-4 py-2 rounded-xl font-semibold transition\">\n",
        "        Enviar\n",
        "      </button>\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <script>\n",
        "    let session_id = Math.random().toString(36).substring(7);\n",
        "\n",
        "    function appendMessage(sender, text) {\n",
        "      let chat = document.getElementById(\"chat\");\n",
        "      let msgDiv = document.createElement(\"div\");\n",
        "      msgDiv.classList.add(\"chat-bubble\", sender === \"user\" ? \"user-msg\" : \"bot-msg\", \"fade-in\");\n",
        "      msgDiv.innerHTML = text;\n",
        "      chat.appendChild(msgDiv);\n",
        "      chat.scrollTop = chat.scrollHeight;\n",
        "    }\n",
        "\n",
        "    async function startChat() {\n",
        "      let r = await fetch('/start/' + session_id);\n",
        "      let data = await r.json();\n",
        "      appendMessage(\"bot\", data.answer);\n",
        "    }\n",
        "\n",
        "    async function send() {\n",
        "      let msgInput = document.getElementById(\"msg\");\n",
        "      let msg = msgInput.value.trim();\n",
        "      if (!msg) return;\n",
        "\n",
        "      appendMessage(\"user\", msg);\n",
        "      msgInput.value = \"\";\n",
        "\n",
        "      let r = await fetch('/chat', {\n",
        "        method: 'POST',\n",
        "        headers: {'Content-Type':'application/json'},\n",
        "        body: JSON.stringify({session_id: session_id, question: msg})\n",
        "      });\n",
        "\n",
        "      let data = await r.json();\n",
        "      appendMessage(\"bot\", data.answer);\n",
        "    }\n",
        "\n",
        "    document.getElementById(\"msg\").addEventListener(\"keypress\", function(e) {\n",
        "      if (e.key === \"Enter\") send();\n",
        "    });\n",
        "\n",
        "    startChat();\n",
        "  </script>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [6432]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "URL pública gerada pelo Ngrok: NgrokTunnel: \"https://operculate-vernon-unmissed.ngrok-free.dev\" -> \"http://localhost:8001\"\n",
            "INFO:     187.255.127.46:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     187.255.127.46:0 - \"GET /start/z43qve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [6432]\n"
          ]
        }
      ],
      "source": [
        "# Executa o App no Colab + ngrok\n",
        "if __name__ == \"__main__\":\n",
        "  #ngrok.set_auth_token(KEY_NGROK) ## Já fizemos essa configuração antes (agora é opcional)\n",
        "  public_url = ngrok.connect(8001)\n",
        "  print(\"URL pública gerada pelo Ngrok:\", public_url)\n",
        "\n",
        "  nest_asyncio.apply()\n",
        "  uvicorn.run(app, host=\"0.0.0.0\", port=8001, reload=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
